{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "# PyTorch 中的循环神经网络模块\n",
        "Earlier we talked about the basics and network structure of the cyclic neural network. Below we teach you how to build a circular neural network under pytorch, because the dynamic graph mechanism of pytorch makes the loop neural network very convenient.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "## General RNN\n",
        "\n",
        "![](https://ws1.sinaimg.cn/large/006tKfTcly1fmt9xz889xj30kb07nglo.jpg)\n",
        "\n",
        "For the simplest RNN, we can use the following two methods: `torch.nn.RNNCell()` and `torch.nn.RNN()`, the difference between the two methods is `RNNCell()` It can only accept single-step input in the sequence, and must pass in the hidden state, and `RNN()` can accept the input of a sequence. By default, it will pass in the hidden state of all 0s, or you can declare the hidden state by itself.\n",
        "\n",
        "The parameters in `RNN()` are\n",
        "\n",
        "Input_size represents the feature dimension of the input $x_t$\n",
        "\n",
        "Hidden_size represents the feature dimension of the output\n",
        "\n",
        "Num_layers represents the number of layers in the network\n",
        "\n",
        "Nonlinearity indicates the optional nonlinear activation function. The default is 'tanh'.\n",
        "\n",
        "Bias indicates whether to use offset, which is used by default\n",
        "\n",
        "Batch_first indicates the form of the input data. The default is False. This is the form, (seq, batch, feature), which means that the sequence length is placed first and the batch is placed second.\n",
        "\n",
        "Dropout indicates whether to apply dropout at the output layer\n",
        "\n",
        "Bidirectional indicates whether to use bidirectional rnn, the default is False\n",
        "\n",
        "For `RNNCell()`, there are fewer parameters, only input_size, hidden_size, bias, and nonlinearity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Define a single step rnn\n",
        "rnn_single = nn.RNNCell(input_size=100, hidden_size=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "1.00000e-02 *\n",
              " 6.2260 -5.3805  3.5870  ...  -2.2162  6.2760  1.6760\n",
              "-5.1878 -4.6751 -5.5926  ...  -1.8942  0.1589  1.0725\n",
              " 3.3236 -3.2726  5.5399  ...   3.3193  0.2117  1.1730\n",
              "          ...             ⋱             ...          \n",
              " 2.4032 -3.4415  5.1036  ...  -2.2035 -0.1900 -6.4016\n",
              " 5.2031 -1.5793 -0.0623  ...   0.3424  6.9412  6.3707\n",
              "-5.4495  4.5280  2.1774  ...   1.8767  2.4968  5.3403\n",
              "[torch.FloatTensor of size 200x200]"
            ]
          },
          "execution_count": 48,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# access the parameters\n",
        "rnn_single.weight_hh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Construct a sequence with a length of 6, batch is 5, and the feature is 100\n",
        "x = Variable(torch.randn(6, 5, 100)) # This is the input format of rnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Define the initial memory state\n",
        "h_t = Variable(torch.zeros(5, 200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#入 rnn\n",
        "out = []\n",
        "For i in range(6): # acts on the entire sequence by looping 6 times\n",
        "    h_t = rnn_single(x[i], h_t)\n",
        "    out.append(h_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Variable containing:\n",
              " 0.0136  0.3723  0.1704  ...   0.4306 -0.7909 -0.5306\n",
              "-0.2681 -0.6261 -0.3926  ...   0.1752  0.5739 -0.2061\n",
              "-0.4918 -0.7611  0.2787  ...   0.0854 -0.3899  0.0092\n",
              " 0.6050  0.1852 -0.4261  ...  -0.7220  0.6809  0.1825\n",
              "-0.6851  0.7273  0.5396  ...  -0.7969  0.6133 -0.0852\n",
              "[torch.FloatTensor of size 5x200]"
            ]
          },
          "execution_count": 52,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "h_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 54,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 200])"
            ]
          },
          "execution_count": 55,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Out[0].shape # Dimensions of each output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "It can be seen that after rnn, the value of the hidden state has been changed because the network memorizes the information in the sequence and outputs 6 results at the same time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "Let's take a look at the case of using `RNN` directly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "rnn_seq = nn.RNN(100, 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "1.00000e-02 *\n",
              " 1.0998 -1.5018 -1.4337  ...   3.8385 -0.8958 -1.6781\n",
              " 5.3302 -5.4654  5.5568  ...   4.7399  5.4110  3.6170\n",
              " 1.0788 -0.6620  5.7689  ...  -5.0747 -2.9066  0.6152\n",
              "          ...             ⋱             ...          \n",
              "-5.6921  0.1843 -0.0803  ...  -4.5852  5.6194 -1.4734\n",
              " 4.4306  6.9795 -1.5736  ...   3.4236 -0.3441  3.1397\n",
              " 7.0349 -1.6120 -4.2840  ...  -5.5676  6.8897  6.1968\n",
              "[torch.FloatTensor of size 200x200]"
            ]
          },
          "execution_count": 33,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# access the parameters\n",
        "rnn_seq.weight_hh_l0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "Out, h_t = rnn_seq(x) # Use the default all 0 hidden state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Variable containing:\n",
              "( 0 ,.,.) = \n",
              "  0.2012  0.0517  0.0570  ...   0.2316  0.3615 -0.1247\n",
              "  0.5307  0.4147  0.7881  ...  -0.4138 -0.1444  0.3602\n",
              "  0.0882  0.4307  0.3939  ...   0.3244 -0.4629 -0.2315\n",
              "  0.2868  0.7400  0.6534  ...   0.6631  0.2624 -0.0162\n",
              "  0.0841  0.6274  0.1840  ...   0.5800  0.8780  0.4301\n",
              "[torch.FloatTensor of size 1x5x200]"
            ]
          },
          "execution_count": 36,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "h_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 35,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "Here h_t is the last hidden state of the network, and the network also outputs 6 results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Define the initial hidden state\n",
        "h_0 = Variable(torch.randn(1, 5, 200))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "The size of the hidden state here has three dimensions, namely (num_layers * num_direction, batch, hidden_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "out, h_t = rnn_seq(x, h_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Variable containing:\n",
              "( 0 ,.,.) = \n",
              "  0.2091  0.0353  0.0625  ...   0.2340  0.3734 -0.1307\n",
              "  0.5498  0.4221  0.7877  ...  -0.4143 -0.1209  0.3335\n",
              "  0.0757  0.4204  0.3826  ...   0.3187 -0.4626 -0.2336\n",
              "  0.3106  0.7355  0.6436  ...   0.6611  0.2587 -0.0338\n",
              "  0.1025  0.6350  0.1943  ...   0.5720  0.8749  0.4525\n",
              "[torch.FloatTensor of size 1x5x200]"
            ]
          },
          "execution_count": 42,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "h_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([6, 5, 200])"
            ]
          },
          "execution_count": 45,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "The result of the simultaneous output is also (seq, batch, feature)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "In general, we use `nn.RNN()` instead of `nn.RNNCell()`, because `nn.RNN()` can avoid us manually writing loops, which is very convenient, and if not specified, we also Will choose to initialize the hidden state with the default all 0s\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "![](https://ws1.sinaimg.cn/large/006tKfTcly1fmt9qj3uhmj30iz07ct90.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true
      },
      "source": [
        "The LSTM is the same as the basic RNN. Its parameters are the same. At the same time, he also has two forms: `nn.LSTMCell()` and `nn.LSTM()`, which are the same as the previous ones. We will not Again, let's take a small example below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "Lstm_seq = nn.LSTM(50, 100, num_layers=2) # Input dimension 100, output 200, two layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "1.00000e-02 *\n",
              " 3.8420  5.7387  6.1351  ...   1.2680  0.9890  1.3037\n",
              "-4.2301  6.8294 -4.8627  ...  -6.4147  4.3015  8.4103\n",
              " 9.4411  5.0195  9.8620  ...  -1.6096  9.2516 -0.6941\n",
              "          ...             ⋱             ...          \n",
              " 1.2930 -1.3300 -0.9311  ...  -6.0891 -0.7164  3.9578\n",
              " 9.0435  2.4674  9.4107  ...  -3.3822 -3.9773 -3.0685\n",
              "-4.2039 -8.2992 -3.3605  ...   2.2875  8.2163 -9.3277\n",
              "[torch.FloatTensor of size 400x100]"
            ]
          },
          "execution_count": 80,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Lstm_seq.weight_hh_l0 # h_t weight of the first layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "**Little exercise: Think about why the size of this coefficient is (400, 100)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Lstm_input = Variable(torch.randn(10, 3, 50)) # Sequence 10, batch is 3, input dimension 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "Out, (h, c) = lstm_seq(lstm_input) # Use the default all 0 hidden state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "Note that there are two hidden states of the LSTM output, h and c, which are the two arrows between each cell in the above figure. The two hidden states are the same size (num_layers * direction, batch, feature )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 100])"
            ]
          },
          "execution_count": 66,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "H.shape # two layers, Batch is 3, feature is 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 100])"
            ]
          },
          "execution_count": 67,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 100])"
            ]
          },
          "execution_count": 61,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "We can not use the default hidden state, which is the need to pass in two tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "h_init = Variable(torch.randn(2, 3, 100))\n",
        "c_init = Variable(torch.randn(2, 3, 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "out, (h, c) = lstm_seq(lstm_input, (h_init, c_init))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 100])"
            ]
          },
          "execution_count": 70,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "h.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 100])"
            ]
          },
          "execution_count": 71,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 100])"
            ]
          },
          "execution_count": 72,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "# GRU\n",
        "![](https://ws3.sinaimg.cn/large/006tKfTcly1fmtaj38y9sj30io06bmxc.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "The GRU and the two mentioned above are the same. I won’t go into details or demonstrate the example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "gru_seq = nn.GRU(10, 20)\n",
        "gru_input = Variable(torch.randn(3, 32, 10))\n",
        "\n",
        "out, h = gru_seq(gru_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              " 0.0766 -0.0548 -0.2008  ...  -0.0250 -0.1819  0.1453\n",
              "-0.1676  0.1622  0.0417  ...   0.1905 -0.0071 -0.1038\n",
              " 0.0444 -0.1516  0.2194  ...  -0.0009  0.0771  0.0476\n",
              "          ...             ⋱             ...          \n",
              " 0.1698 -0.1707  0.0340  ...  -0.1315  0.1278  0.0946\n",
              " 0.1936  0.1369 -0.0694  ...  -0.0667  0.0429  0.1322\n",
              " 0.0870 -0.1884  0.1732  ...  -0.1423 -0.1723  0.2147\n",
              "[torch.FloatTensor of size 60x20]"
            ]
          },
          "execution_count": 76,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gru_seq.weight_hh_l0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 20])"
            ]
          },
          "execution_count": 75,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "h.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 20])"
            ]
          },
          "execution_count": 74,
          "metadata": {
            
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out.shape"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mx",
      "language": "python",
      "name": "mx"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}