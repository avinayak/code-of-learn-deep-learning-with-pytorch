{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true
      },
      "source": [
        "# 变分自动编码器\n",
        "A variation encoder is an upgraded version of an automatic encoder. Its structure is similar to that of an automatic encoder, and it is also composed of an encoder and a decoder.\n",
        "\n",
        "Recall that the autoencoder has a problem, that is, it can't generate images arbitrarily, because we can't construct hidden vectors by ourselves. We need to input the encoding through an image to know what the hidden vector is. Then we can This problem is solved by a variable-segment automatic encoder.\n",
        "\n",
        "In fact, the principle is particularly simple, only need to add some restrictions to the encoding process, forcing the generated implicit vector to roughly follow a standard normal distribution, which is the biggest difference from the general automatic encoder.\n",
        "\n",
        "So that we generate a new image is very simple, we only need to give it a standard normal distribution of random implied vectors, so that we can generate the image we want through the decoder, without giving it a raw picture First code.\n",
        "\n",
        "In general, the implicit vector we get through the encoder is not a standard normal distribution. To measure the similarity between the two distributions, we use KL divergence, which is used to represent the difference between the implicit vector and the standard normal distribution. The loss, another loss is still represented by the mean square error of the generated image and the original image.\n",
        "\n",
        "The formula for KL divergence is as follows\n",
        "\n",
        "$$\n",
        "D{KL} (P || Q) =  \\int_{-\\infty}^{\\infty} p(x) \\log \\frac{p(x)}{q(x)} dx\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "## 重Para\n",
        "To avoid calculating the integrals in KL divergence, we use the technique of re-parameters instead of generating an implicit vector each time, but generating two vectors, one for the mean and one for the standard deviation. Here we default the implicit vector after encoding. After obeying a normal distribution, a normal distribution can be multiplied by the standard deviation plus the mean to synthesize the normal distribution. Finally, loss is expected to produce a normal distribution that conforms to a standard normal distribution. That is, the mean is 0 and the variance is 1\n",
        "\n",
        "So the standard variable-segment automatic encoder is as follows\n",
        "\n",
        "![](https://ws4.sinaimg.cn/large/006tKfTcgy1fn15cq6n7pj30k007t0sv.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "So in the end we can define our loss as the following function, summed by mean square error and KL divergence to get a total loss\n",
        "\n",
        "```\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    \"\"\"\n",
        "    recon_x: generating images\n",
        "    x: origin images\n",
        "    mu: latent mean\n",
        "    logvar: latent log variance\n",
        "    \"\"\"\n",
        "    MSE = reconstruction_function(recon_x, x)\n",
        "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
        "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
        "    # KL divergence\n",
        "    return MSE + KLD\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "Below we use the mnist data set to briefly explain the variable automatic encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-01T10:41:05.738797Z",
          "start_time": "2018-01-01T10:41:05.215490Z"
        },
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms as tfs\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-01T10:41:05.769643Z",
          "start_time": "2018-01-01T10:41:05.741302Z"
        },
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "im_tfs = tfs.Compose([\n",
        "    tfs.ToTensor(),\n",
        "tfs.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) # standardization\n",
        "])\n",
        "\n",
        "train_set = MNIST('./mnist', transform=im_tfs)\n",
        "train_data = DataLoader(train_set, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-01T10:41:06.397118Z",
          "start_time": "2018-01-01T10:41:06.306479Z"
        },
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(784, 400)\n",
        "        self.fc21 = nn.Linear(400, 20) # mean\n",
        "        self.fc22 = nn.Linear(400, 20) # var\n",
        "        self.fc3 = nn.Linear(20, 400)\n",
        "        self.fc4 = nn.Linear(400, 784)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return self.fc21(h1), self.fc22(h1)\n",
        "\n",
        "    def reparametrize(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        eps = torch.FloatTensor(std.size()).normal_()\n",
        "        if torch.cuda.is_available():\n",
        "            eps = Variable(eps.cuda())\n",
        "        else:\n",
        "            eps = Variable(eps)\n",
        "        return eps.mul(std).add_(mu)\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return F.tanh(self.fc4(h3))\n",
        "\n",
        "    def forward(self, x):\n",
        "Mu, logvar = self.encode(x) #编码\n",
        "z = self.reparametrize(mu, logvar) # Re-parameterized to a normal distribution\n",
        "Return self.decode(z), mu, logvar # decode, and output mean variance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-01T10:41:10.056600Z",
          "start_time": "2018-01-01T10:41:06.430817Z"
        },
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "Net = VAE() # instantiate the network\n",
        "if torch.cuda.is_available():\n",
        "    net = net.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-01T10:41:10.409900Z",
          "start_time": "2018-01-01T10:41:10.059597Z"
        },
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "x, _ = train_set[0]\n",
        "x = x.view(x.shape[0], -1)\n",
        "if torch.cuda.is_available():\n",
        "    x = x.cuda()\n",
        "x = Variable(x)\n",
        "_, mu, var = net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-01T10:41:29.753678Z",
          "start_time": "2018-01-01T10:41:29.749178Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variable containing:\n",
            "\n",
            "Columns 0 to 9 \n",
            "-0.0307 -0.1439 -0.0435  0.3472  0.0368 -0.0339  0.0274 -0.5608  0.0280  0.2742\n",
            "\n",
            "Columns 10 to 19 \n",
            "-0.6221 -0.0894 -0.0933  0.4241  0.1611  0.3267  0.5755 -0.0237  0.2714 -0.2806\n",
            "[torch.cuda.FloatTensor of size 1x20 (GPU 0)]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(mu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "It can be seen that for the input, the network can output the mean and variance of the implicit variables, where the mean variance is not yet trained.\n",
        "\n",
        "Start training below\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-01T10:13:54.560436Z",
          "start_time": "2018-01-01T10:13:54.530108Z"
        },
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "reconstruction_function = nn.MSELoss(size_average=False)\n",
        "\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    \"\"\"\n",
        "    recon_x: generating images\n",
        "    x: origin images\n",
        "    mu: latent mean\n",
        "    logvar: latent log variance\n",
        "    \"\"\"\n",
        "    MSE = reconstruction_function(recon_x, x)\n",
        "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
        "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
        "    # KL divergence\n",
        "    return MSE + KLD\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
        "\n",
        "def to_img(x):\n",
        "    '''\n",
        "Define a function to convert the final result back to the image\n",
        "    '''\n",
        "    x = 0.5 * (x + 1.)\n",
        "    x = x.clamp(0, 1)\n",
        "    x = x.view(x.shape[0], 1, 28, 28)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-01T10:35:01.115877Z",
          "start_time": "2018-01-01T10:13:54.562533Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 20, Loss: 61.5803\n",
            "epoch: 40, Loss: 62.9573\n",
            "epoch: 60, Loss: 63.4285\n",
            "epoch: 80, Loss: 64.7138\n",
            "epoch: 100, Loss: 63.3343\n"
          ]
        }
      ],
      "source": [
        "for e in range(100):\n",
        "    for im, _ in train_data:\n",
        "        im = im.view(im.shape[0], -1)\n",
        "        im = Variable(im)\n",
        "        if torch.cuda.is_available():\n",
        "            im = im.cuda()\n",
        "        recon_im, mu, logvar = net(im)\n",
        "loss = loss_function(recon i'm, in, my, lover)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (e + 1) % 20 == 0:\n",
        "        print('epoch: {}, Loss: {:.4f}'.format(e + 1, loss.data[0]))\n",
        "        save = to_img(recon_im.cpu().data)\n",
        "        if not os.path.exists('./vae_img'):\n",
        "            os.mkdir('./vae_img')\n",
        "        save_image(save, './vae_img/image_{}.png'.format(e + 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "You can look at the results obtained with the variable-point auto-encoder, you can find that the effect is much better than the average encoder\n",
        "\n",
        "![](https://ws1.sinaimg.cn/large/006tKfTcgy1fn1ag8832zj306q0a2gmz.jpg)\n",
        "\n",
        "We can output the mean value of it\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-01T10:40:36.481622Z",
          "start_time": "2018-01-01T10:40:36.463332Z"
        },
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "x, _ = train_set[0]\n",
        "x = x.view(x.shape[0], -1)\n",
        "if torch.cuda.is_available():\n",
        "    x = x.cuda()\n",
        "x = Variable(x)\n",
        "_, mu, _ = net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-01T10:40:37.490484Z",
          "start_time": "2018-01-01T10:40:37.485127Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variable containing:\n",
            "\n",
            "Columns 0 to 9 \n",
            " 0.3861  0.5561  1.1995 -1.6773  0.9867  0.1244 -0.3443 -1.6658  1.3332  1.1606\n",
            "\n",
            "Columns 10 to 19 \n",
            " 0.6898  0.3042  2.1044 -2.4588  0.0504  0.9743  1.1136  0.7872 -0.0777  1.6101\n",
            "[torch.cuda.FloatTensor of size 1x20 (GPU 0)]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(mu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        
      },
      "source": [
        "Although the variational autoencoder is better than the general autoencoder and limits the probability distribution of the output code, it still generates the loss by directly calculating the mean square error of the generated picture and the original picture. This method is not good. In the next chapter to generate a confrontation network, we will talk about the limitations of this method of calculating loss, and then introduce a new training method, which is to train the network by generating confrontation training methods instead of Directly compare the mean square error of each pixel of two images\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}